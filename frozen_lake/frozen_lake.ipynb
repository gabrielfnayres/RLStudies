{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f159cdd-480a-474f-84b6-2210ad7ff13f",
   "metadata": {},
   "source": [
    " # Initializing the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6256a3bc-bc43-4fa4-9169-34344ad2dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8f427f57-faa3-4703-bbc7-3d3776f16409",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"8x8\", is_slippery=False, render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17452645-89d7-4c69-a704-a6a4435eb8d5",
   "metadata": {},
   "source": [
    "## Printing the env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b6c4ab37-c7c8-4af0-b2ff-2eb14b6cf177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION SPACE \n",
      "\n",
      "observation space Discrete(64)\n",
      "simple observation 33\n"
     ]
    }
   ],
   "source": [
    "print(\"OBSERVATION SPACE \\n\")\n",
    "print(\"observation space\", env.observation_space)\n",
    "print(\"simple observation\", env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "026fa0a6-f0fe-4924-9e6a-c116f5d3d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION SPACE \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 0\n"
     ]
    }
   ],
   "source": [
    "print(\"ACTION SPACE \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8a11b-a002-4f30-9e5a-d99164151b58",
   "metadata": {},
   "source": [
    "## Initializing the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6c6f63ec-2506-4fb4-805c-0010c3883c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space:  64\n",
      "observation space:  64\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"state space: \", state_space)\n",
    "\n",
    "action_space = env.observation_space.n\n",
    "print(\"observation space: \", action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "48ec4a87-48a9-4419-b319-07a58991c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qtable(state_space, action_space):\n",
    "    q_table = np.zeros((state_space, action_space))\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f5f9ca41-ccf7-4f15-8518-e1133da8443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_frozen_lake = initialize_qtable(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c42f6-77a4-48fb-8f4c-e92250f99cce",
   "metadata": {},
   "source": [
    "## Defining the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5c084d02-d87a-4a0d-9593-990aed1de174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(qtable, state):\n",
    "    action = np.argmax(qtable[state][:])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c78c2-ba40-481b-8737-31754a377088",
   "metadata": {},
   "source": [
    "## Defining epsilon-greedy-policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "90385d84-171c-4199-aebe-7c12fc37a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(qtable, state, epsilon):\n",
    "    random_num  = random.uniform(0,1)\n",
    "\n",
    "    if random_num > epsilon:\n",
    "\n",
    "        action = greedy_policy(qtable, state)\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "96c7f875-21d9-4938-85f5-301cd1a237b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_greedy_policy(q_table_frozen_lake, env.action_space.sample(), 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7df56e-ce4d-462e-b547-5e814610b85f",
   "metadata": {},
   "source": [
    "## Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "29b1e32d-d4ad-48c4-a1c4-2afec8df053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1000\n",
    "learning_rate = 0.7\n",
    "evaluation_episodes = 100\n",
    "\n",
    "env_id = \"Frozen_lake_ayres\"\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "eval_seed = []\n",
    "\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.05\n",
    "decay_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30419f00-3759-4db0-b8aa-911e355ae4af",
   "metadata": {},
   "source": [
    "## Trainig the agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6223d8f2-689e-495e-ab71-86267134dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, qtable):\n",
    "    # it reduces the epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episodes)\n",
    "\n",
    "    state, info = env.reset()\n",
    "    step = 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action = epsilon_greedy_policy(qtable, state, epsilon)\n",
    "\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "        #creating the q-table\n",
    "        qtable[state][action] = qtable[state][action] + learning_rate*(reward + gamma*np.max(qtable[new_state]) - qtable[state][action])\n",
    "\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        state = new_state\n",
    "    return qtable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf1196-ff07-424c-bab2-bd2bbbaac773",
   "metadata": {},
   "source": [
    "## Training the q-learning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2c89c580-1ef5-4acd-8b29-a66fa3dff162",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_frozenlake = train(episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, q_table_frozen_lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5476885b-71af-4b54-b244-98021ec6786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table_frozen_lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb28dea-10de-4a20-9b0d-b5e5c3e12835",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ed67f9e3-7395-4e81-81de-9cac930bd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, evaluation_episodes, qtable, seed):\n",
    " \n",
    "  episode_rewards = []\n",
    "  for episode in tqdm(range(evaluation_episodes)):\n",
    "    if seed:\n",
    "      state, info = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state, info = env.reset()\n",
    "    step = 0\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    total_rewards_ep = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "      \n",
    "      action = greedy_policy(qtable, state)\n",
    "      new_state, reward, terminated, truncated, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "\n",
    "      if terminated or truncated:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7977175f-a638-4b55-bdb5-9327359c795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1380.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_reward=0.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, evaluation_episodes, q_table_frozen_lake, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72273bf-c3a5-4ffc-9d95-6757b6335b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
